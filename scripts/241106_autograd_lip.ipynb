{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `auto_norm` to compute output norms and optimize scaling factors\n",
    "\n",
    "We go through three examples using `auto_norm`:\n",
    "1. Compute norms automatically for regular PyTorch modules\n",
    "2. Build modula norm automatically for regular PyTorch modules\n",
    "3. Optimize scaling factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex1: compute norms automatically for regular PyTorch modules\n",
    "\n",
    "Let's define a usual network in normal PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyResBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`auto_norm` provides computation on `auto_norm.NormedTensorBase` subclasses, including \n",
    "+ `RMS_NormTensor`, \n",
    "+ `RMS_RMS_NormTensor`, \n",
    "+ `L1_NormTensor` and \n",
    "+ `Linf_NormTensor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`auto_norm.build_norm_map` is the key entrypoint, it returns a `norm_map` function that computes computes (norms of inputs, norms of parameters, norms of buffers) -> norms of outputs.\n",
    "\n",
    "Its syntax is\n",
    "\n",
    "```py\n",
    "def build_norm_map(module: nn.Module, *example_args, dynamic_shapes: Optional = None, **example_kwargs):\n",
    "    ...\n",
    "\n",
    "    def norm_map(*normed_args, normed_state_dict, **normed_kwargs):\n",
    "        # normed_* should generally contain auto_norm.*_NormTensor, instead of usual torch.Tensor\n",
    "        ...\n",
    "        return normed_outputs\n",
    "\n",
    "    return norm_map\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %p_net_0_weight : [num_users=1] = placeholder[target=p_net_0_weight]\n",
      "    %p_net_0_bias : [num_users=1] = placeholder[target=p_net_0_bias]\n",
      "    %p_net_2_weight : [num_users=1] = placeholder[target=p_net_2_weight]\n",
      "    %p_net_2_bias : [num_users=1] = placeholder[target=p_net_2_bias]\n",
      "    %p_net_4_weight : [num_users=1] = placeholder[target=p_net_4_weight]\n",
      "    %p_net_4_bias : [num_users=1] = placeholder[target=p_net_4_bias]\n",
      "    %x : [num_users=2] = placeholder[target=x]\n",
      "    %op__wrapper__torch__c__nn_linear__4507253904 : [num_users=1] = call_function[target=torch.ops.auto_norm.op__wrapper__torch__C__nn_linear__4507253904.default](args = (%x, %p_net_0_weight, %p_net_0_bias), kwargs = {})\n",
      "    %op__wrapper__torch__ops_aten_aten_relu__4876676816 : [num_users=1] = call_function[target=torch.ops.auto_norm.op__wrapper__torch__ops_aten_aten_relu__4876676816.default](args = (%op__wrapper__torch__c__nn_linear__4507253904,), kwargs = {})\n",
      "    %op__wrapper__torch__c__nn_linear__4507253905 : [num_users=1] = call_function[target=torch.ops.auto_norm.op__wrapper__torch__C__nn_linear__4507253904.default](args = (%op__wrapper__torch__ops_aten_aten_relu__4876676816, %p_net_2_weight, %p_net_2_bias), kwargs = {})\n",
      "    %op__wrapper__torch__ops_aten_aten_relu__4876676817 : [num_users=1] = call_function[target=torch.ops.auto_norm.op__wrapper__torch__ops_aten_aten_relu__4876676816.default](args = (%op__wrapper__torch__c__nn_linear__4507253905,), kwargs = {})\n",
      "    %op__wrapper__torch__c__nn_linear__4507253906 : [num_users=1] = call_function[target=torch.ops.auto_norm.op__wrapper__torch__C__nn_linear__4507253904.default](args = (%op__wrapper__torch__ops_aten_aten_relu__4876676817, %p_net_4_weight, %p_net_4_bias), kwargs = {})\n",
      "    %op__wrapper__torch__ops_aten_aten_add_tensor__4693374800 : [num_users=1] = call_function[target=torch.ops.auto_norm.op__wrapper__torch__ops_aten_aten_add_Tensor__4693374800.default](args = (%x, %op__wrapper__torch__c__nn_linear__4507253906), kwargs = {})\n",
      "    return (op__wrapper__torch__ops_aten_aten_add_tensor__4693374800,)\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, p_net_0_weight, p_net_0_bias, p_net_2_weight, p_net_2_bias, p_net_4_weight, p_net_4_bias, x):\n",
      "    op__wrapper__torch__c__nn_linear__4507253904 = torch.ops.auto_norm.op__wrapper__torch__C__nn_linear__4507253904.default(x, p_net_0_weight, p_net_0_bias);  p_net_0_weight = p_net_0_bias = None\n",
      "    op__wrapper__torch__ops_aten_aten_relu__4876676816 = torch.ops.auto_norm.op__wrapper__torch__ops_aten_aten_relu__4876676816.default(op__wrapper__torch__c__nn_linear__4507253904);  op__wrapper__torch__c__nn_linear__4507253904 = None\n",
      "    op__wrapper__torch__c__nn_linear__4507253905 = torch.ops.auto_norm.op__wrapper__torch__C__nn_linear__4507253904.default(op__wrapper__torch__ops_aten_aten_relu__4876676816, p_net_2_weight, p_net_2_bias);  op__wrapper__torch__ops_aten_aten_relu__4876676816 = p_net_2_weight = p_net_2_bias = None\n",
      "    op__wrapper__torch__ops_aten_aten_relu__4876676817 = torch.ops.auto_norm.op__wrapper__torch__ops_aten_aten_relu__4876676816.default(op__wrapper__torch__c__nn_linear__4507253905);  op__wrapper__torch__c__nn_linear__4507253905 = None\n",
      "    op__wrapper__torch__c__nn_linear__4507253906 = torch.ops.auto_norm.op__wrapper__torch__C__nn_linear__4507253904.default(op__wrapper__torch__ops_aten_aten_relu__4876676817, p_net_4_weight, p_net_4_bias);  op__wrapper__torch__ops_aten_aten_relu__4876676817 = p_net_4_weight = p_net_4_bias = None\n",
      "    op__wrapper__torch__ops_aten_aten_add_tensor__4693374800 = torch.ops.auto_norm.op__wrapper__torch__ops_aten_aten_add_Tensor__4693374800.default(x, op__wrapper__torch__c__nn_linear__4507253906);  x = op__wrapper__torch__c__nn_linear__4507253906 = None\n",
      "    return (op__wrapper__torch__ops_aten_aten_add_tensor__4693374800,)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import auto_norm as auto_norm\n",
    "\n",
    "net = MyResBlock()\n",
    "example_input = torch.randn(10, 8, requires_grad=True)\n",
    "\n",
    "norm_map = auto_norm.build_norm_map(net, example_input)  # can also specify dynamic dims (e.g., batch), but not necessary for this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct normed input and state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable debug level logging\n",
    "import logging, sys\n",
    "logger = auto_norm.logger\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normed_input: \n",
      " RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1,), ...)\n"
     ]
    }
   ],
   "source": [
    "normed_input = auto_norm.RMS_NormTensor(1, elem_dims=(-1,))\n",
    "print('normed_input: \\n', normed_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normed_state_dict:\n",
      "{'net.0.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.0.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.2.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.2.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.4.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.4.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...)}\n"
     ]
    }
   ],
   "source": [
    "normed_state_dict = {}\n",
    "for name in net.state_dict():\n",
    "    if name.endswith('weight'):\n",
    "        normed_state_dict[name] = auto_norm.RMS_RMS_NormTensor(1, elem_dims=(-1, -2))  # elem_dims means which dims to norm over\n",
    "    elif name.endswith('bias'):\n",
    "        normed_state_dict[name] = auto_norm.RMS_NormTensor(0, elem_dims=(-1,))\n",
    "\n",
    "print('normed_state_dict:')\n",
    "from pprint import pprint\n",
    "pprint(normed_state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `norm_map` to compute the output norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "output_norm: \n",
      " RMS_NormTensor(\n",
      "    norm_size=tensor(1.5000),\n",
      "    elem_dims=(1,),\n",
      "    unwrapped=FakeTensor(..., size=(10, 8)),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "output_norm = norm_map(normed_input, normed_state_dict=normed_state_dict)\n",
    "print('output_norm: \\n', output_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.overrides import enable_reentrant_dispatch\n",
    "from torch._subclasses.fake_tensor import FakeTensorMode\n",
    "\n",
    "fake_mode = FakeTensorMode(allow_non_fake_inputs=True)\n",
    "\n",
    "@torch.library.custom_op(\"mylib::foo\", mutates_args={}, schema=\"(Tensor x) -> Tensor\")\n",
    "def foo(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x.clone()\n",
    "\n",
    "@foo.register_fake\n",
    "def foo_fake(x: torch.Tensor) -> torch.Tensor:\n",
    "    print('fake')\n",
    "    return x\n",
    "\n",
    "@torch.library.custom_op(\"mylib::foo1\", mutates_args={}, schema=\"(Tensor x) -> Tensor\")\n",
    "def foo1(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x.clone()\n",
    "\n",
    "@foo1.register_fake\n",
    "def foo1_fake(x: torch.Tensor) -> torch.Tensor:\n",
    "    print('fake')\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "_x = 1\n",
    "\n",
    "class MyMode(torch.utils._python_dispatch.TorchDispatchMode):\n",
    "    def __torch_dispatch__(self, func, types, args=(), kwargs=None):\n",
    "        global _x\n",
    "        print('mode', func, types)\n",
    "        return func(*args, **kwargs)\n",
    "        return NotImplemented\n",
    "        if _x == 1:\n",
    "            with enable_reentrant_dispatch(), self:\n",
    "                _x += 1\n",
    "                return func(*args, **kwargs)\n",
    "        else:\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "@torch.library.register_torch_dispatch(\"mylib::foo\", MyMode)\n",
    "def _(mode, func, types, args, kwargs):\n",
    "    print('dispatch')\n",
    "    x, = args\n",
    "    # z = foo1(x)\n",
    "    # return z + 1\n",
    "    with enable_reentrant_dispatch(), mode:\n",
    "        z = foo1(x)\n",
    "    print(z)\n",
    "    return z\n",
    "\n",
    "@torch.library.register_torch_dispatch(\"mylib::foo1\", MyMode)\n",
    "def _(mode, func, types, args, kwargs):\n",
    "    print('dispatch 1')\n",
    "    x, = args\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispatch\n",
      "dispatch 1\n",
      "tensor([ 1.0699, -0.1113,  2.8711], requires_grad=True)\n",
      "mode aten.view.default ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0699, -0.1113,  2.8711],\n",
       "       grad_fn=<GeneratedBackwardFor_mylib_foo_defaultBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3).requires_grad_()\n",
    "with MyMode():\n",
    "    y = foo(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass dispatch aten.resize_.default (<class '__main__.MyT'>,)\n",
      "subclass dispatch aten.normal_.default (<class '__main__.MyT'>,)\n",
      "---\n",
      "subclass dispatch mylib.foo.default (<class '__main__.MyT'>,)\n",
      "--===\n",
      "subclass dispatch aten.allclose.default (<class '__main__.MyT'>,)\n",
      "---\n",
      "mode mylib.foo.default (<class '__main__.MyT'>,)\n",
      "subclass dispatch mylib.foo.default (<class '__main__.MyT'>,)\n",
      "--===\n",
      "---\n",
      "dispatch\n",
      "fake\n",
      "FakeTensor(..., size=(3,))\n",
      "fake\n",
      "--===\n",
      "dispatch\n",
      "subclass dispatch mylib.foo.default (<class '__main__.MyT'>,)\n",
      "subclass dispatch aten.reshape.default (<class '__main__.MyT'>,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": ".tolist() is not supported for tensor subclasses, got MyT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m     y \u001b[38;5;241m=\u001b[39m foo(fake_mode\u001b[38;5;241m.\u001b[39mfake_tensor_converter\u001b[38;5;241m.\u001b[39mfrom_real_tensor(fake_mode, x))\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--===\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m     y \u001b[38;5;241m=\u001b[39m foo(x)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--===\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(y, x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_library/custom_ops.py:669\u001b[0m, in \u001b[0;36mCustomOpDef.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opoverload(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_ops.py:716\u001b[0m, in \u001b[0;36mOpOverload.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_library/autograd.py:113\u001b[0m, in \u001b[0;36mmake_autograd_impl.<locals>.autograd_impl\u001b[0;34m(keyset, *args, **keyword_only_args)\u001b[0m\n\u001b[1;32m    111\u001b[0m     result \u001b[38;5;241m=\u001b[39m Generated\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, Metadata(keyset, keyword_only_args))  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     result \u001b[38;5;241m=\u001b[39m forward_no_grad(\u001b[38;5;241m*\u001b[39margs, Metadata(keyset, keyword_only_args))\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_library/autograd.py:40\u001b[0m, in \u001b[0;36mmake_autograd_impl.<locals>.forward_no_grad\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     38\u001b[0m keyset \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mkeyset\n\u001b[1;32m     39\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mkeyword_only_args\n\u001b[0;32m---> 40\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mredispatch(keyset \u001b[38;5;241m&\u001b[39m _C\u001b[38;5;241m.\u001b[39m_after_autograd_keyset, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_ops.py:721\u001b[0m, in \u001b[0;36mOpOverload.redispatch\u001b[0;34m(self, keyset, *args, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mredispatch\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, keyset, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 721\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle\u001b[38;5;241m.\u001b[39mredispatch_boxed(keyset, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_library/custom_ops.py:477\u001b[0m, in \u001b[0;36mCustomOpDef.register_torch_dispatch.<locals>.register.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_dispatch_fns[torch_dispatch_class](\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    479\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[11], line 55\u001b[0m, in \u001b[0;36m_\u001b[0;34m(mode, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m enable_reentrant_dispatch():\n\u001b[1;32m     54\u001b[0m     z \u001b[38;5;241m=\u001b[39m foo(x)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m     56\u001b[0m zz \u001b[38;5;241m=\u001b[39m (foo(fake_mode\u001b[38;5;241m.\u001b[39mfake_tensor_converter\u001b[38;5;241m.\u001b[39mfrom_real_tensor(fake_mode, x)))\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:523\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    520\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_tensor_str\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor_str.py:708\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    707\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 708\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _str_intern(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor_str.py:625\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    623\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    624\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 625\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m, indent)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    628\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor_str.py:358\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m _Formatter(get_summarized_data(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor_str.py:280\u001b[0m, in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scalar_str(\u001b[38;5;28mself\u001b[39m, formatter1, formatter2)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vector_str(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter1, formatter2)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems:\n\u001b[1;32m    283\u001b[0m     slices \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    284\u001b[0m         [\n\u001b[1;32m    285\u001b[0m             _tensor_str_with_formatter(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         ]\n\u001b[1;32m    297\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor_str.py:261\u001b[0m, in \u001b[0;36m_vector_str\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    255\u001b[0m     data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    256\u001b[0m         [_val_formatter(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m[: PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems]\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;241m+\u001b[39m [_val_formatter(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m-\u001b[39mPRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems :]\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     data \u001b[38;5;241m=\u001b[39m [_val_formatter(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[1;32m    263\u001b[0m data_lines \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    264\u001b[0m     data[i : i \u001b[38;5;241m+\u001b[39m elements_per_line] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data), elements_per_line)\n\u001b[1;32m    265\u001b[0m ]\n\u001b[1;32m    266\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m data_lines]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: .tolist() is not supported for tensor subclasses, got MyT"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.overrides import enable_reentrant_dispatch\n",
    "from torch._subclasses.fake_tensor import FakeTensorMode\n",
    "\n",
    "fake_mode = FakeTensorMode(allow_non_fake_inputs=True)\n",
    "\n",
    "class MyT(torch.Tensor):\n",
    "    LOL: bool = False\n",
    "    def __torch_dispatch__(self, func, types, args, kwargs):\n",
    "        print('subclass dispatch', func, types)\n",
    "        if MyT.LOL:\n",
    "            return NotImplemented\n",
    "        return super().__torch_dispatch__(func, types, args, kwargs)\n",
    "\n",
    "@torch.library.custom_op(\"mylib::foo\", mutates_args={}, schema=\"(Tensor x) -> Tensor\")\n",
    "def foo(x: MyT) -> MyT:\n",
    "    return x.clone()\n",
    "\n",
    "@foo.register_fake\n",
    "def foo_fake(x: MyT) -> MyT:\n",
    "    print('fake')\n",
    "    return x\n",
    "\n",
    "_x = 1\n",
    "\n",
    "class MyMode(torch.utils._python_dispatch.TorchDispatchMode):\n",
    "    def __torch_dispatch__(self, func, types, args=(), kwargs=None):\n",
    "        global _x\n",
    "        print('mode', func, types)\n",
    "        return NotImplemented\n",
    "        if _x == 1:\n",
    "            with enable_reentrant_dispatch(), self:\n",
    "                _x += 1\n",
    "                return func(*args, **kwargs)\n",
    "        else:\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "\n",
    "x = torch.randn(3, out=MyT(3))\n",
    "print('---')\n",
    "y = foo(x)\n",
    "print('--===')\n",
    "assert torch.allclose(y, x)\n",
    "print('---')\n",
    "with MyMode():\n",
    "    y = foo(x)\n",
    "print('--===')\n",
    "print('---')\n",
    "@torch.library.register_torch_dispatch(\"mylib::foo\", MyMode)\n",
    "def _(mode, func, types, args, kwargs):\n",
    "    print('dispatch')\n",
    "    x, = args\n",
    "    with enable_reentrant_dispatch():\n",
    "        z = foo(x)\n",
    "    print(x)\n",
    "    zz = (foo(fake_mode.fake_tensor_converter.from_real_tensor(fake_mode, x)))\n",
    "    return z + 1\n",
    "# MyT.LOL = True\n",
    "with MyMode():\n",
    "    y = foo(fake_mode.fake_tensor_converter.from_real_tensor(fake_mode, x))\n",
    "    print('--===')\n",
    "    y = foo(x)\n",
    "print('--===')\n",
    "assert torch.allclose(y, x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional\n",
    "\n",
    "from torch.utils._pytree import tree_map\n",
    "from torch.overrides import enable_reentrant_dispatch\n",
    "\n",
    "import contextlib\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from torch.utils._pytree import PyTree, tree_flatten, tree_unflatten\n",
    "\n",
    "# Dumping ground for utilities that should eventual make their way into\n",
    "# PyTorch proper\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def no_dispatch():\n",
    "    guard = torch._C._DisableTorchDispatch()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        del guard\n",
    "\n",
    "\n",
    "def tree_map2(fn: Any, pytree1: PyTree, pytree2: PyTree) -> PyTree:\n",
    "    flat_args1, spec1 = tree_flatten(pytree1)\n",
    "    flat_args2, spec2 = tree_flatten(pytree2)\n",
    "    assert spec1 == spec2\n",
    "    return tree_unflatten([fn(i, j) for i, j in zip(flat_args1, flat_args2)], spec1)\n",
    "\n",
    "\n",
    "# IDK if this is actually useful or not\n",
    "def unmake_subclass(tensor):\n",
    "    with no_dispatch():\n",
    "        return torch.Tensor._make_subclass(torch.Tensor, tensor)\n",
    "\n",
    "\n",
    "def fill_defaults(args, n, defaults_tail):\n",
    "    \"\"\"\n",
    "    __torch_dispatch__ doesn't guarantee the number of arguments you are\n",
    "    passed (e.g., defaulted arguments are not passed); but usually it is\n",
    "    convenient to pad out the arguments list with defaults.  This function\n",
    "    helps you do that.\n",
    "\n",
    "    Args:\n",
    "        args: the list of positional arguments passed to __torch_dispatch__\n",
    "        n: the number of arguments you are expecting to get\n",
    "        defaults_tail: default values for the arguments, starting from the\n",
    "            end of the list\n",
    "\n",
    "    Example:\n",
    "\n",
    "        >>> fill_defaults([1, 2, 3], 5, [3, 4, 5])\n",
    "        [1, 2, 3, 4, 5]\n",
    "        >>> fill_defaults([1, 2, 3], 5, [None, None, None])\n",
    "        [1, 2, 3, None, None]]\n",
    "    \"\"\"\n",
    "    if n - len(defaults_tail) > len(args):\n",
    "        raise RuntimeError(\"not enough defaults to fill arguments\")\n",
    "    r = list(args)\n",
    "    for i in range(len(args), n):\n",
    "        r.append(defaults_tail[i - n + len(defaults_tail)])\n",
    "    return r\n",
    "\n",
    "# All of the tensor examples in this zoo inherit from BaseTensor.  Ideally,\n",
    "# however, they would inherit directly from Tensor.  This is just our staging\n",
    "# ground for applying behavior that hasn't yet made it into core but that\n",
    "# we would like to apply by default.\n",
    "class BaseTensor(torch.Tensor):\n",
    "    # See https://github.com/pytorch/pytorch/pull/73727 ; this is necessary\n",
    "    # to ensure that super().__new__ can cooperate with each other\n",
    "    @staticmethod\n",
    "    def __new__(cls, elem, *, requires_grad=None):\n",
    "        if requires_grad is None:\n",
    "            return super().__new__(cls, elem)\n",
    "        else:\n",
    "            return cls._make_subclass(cls, elem, requires_grad)\n",
    "\n",
    "    # To ensure constructors can cooperate with one another, must accept and\n",
    "    # ignore element tensor (TODO: is this right???)\n",
    "    def __init__(self, elem):\n",
    "        super().__init__()\n",
    "\n",
    "    # If __torch_dispatch__ is defined (which it will be for all our examples)\n",
    "    # the default torch function implementation (which preserves subclasses)\n",
    "    # typically must be disabled\n",
    "    # __torch_function__ = torch._C._disabled_torch_function_impl\n",
    "\n",
    "# This file describes how to use wrapper tensors (ala TrivialTensorViaComposition)\n",
    "# to override autograd from __torch_dispatch__.  Ordinarily,\n",
    "# __torch_dispatch__ runs after autograd, so you have no way of overriding\n",
    "# the autograd behavior (since it will be handled after you return).  However,\n",
    "# if we put the autograd tensor *inside* a wrapper tensor (which doesn't\n",
    "# itself require gradients), we get a chance to interpose (in __torch_dispatch__)\n",
    "# before you handle gradients on the inner element.\n",
    "#\n",
    "# Note that you can also use __torch_function__ instead to implement this\n",
    "# functionality, so this is mostly a question of whether or not you want to\n",
    "# target the public Python API, or the internal ATen operators API\n",
    "# (torch.ops.aten).\n",
    "\n",
    "\n",
    "class InnerAutogradTensor(torch.Tensor):\n",
    "    REG = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def __new__(cls, elem, *, requires_grad=None):\n",
    "        # Outer tensor's autograd is now disconnected from the inner\n",
    "        # tensors autograd...\n",
    "        # return super().__new__(cls, elem, requires_grad=False)\n",
    "        return cls._make_wrapper_subclass(cls, elem.size(), dtype=elem.dtype,\n",
    "                                          device=elem.device,\n",
    "                                          requires_grad=False)  # NB: false here so that we can use reentrant dispatch on unwrapped normed tensors to get autograd on norms\n",
    "\n",
    "    def __init__(self, elem):\n",
    "        # ... but note that we save the inner tensor, so we can still\n",
    "        # do autograd on operations on the inside!\n",
    "        self.elem = elem\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.requires_grad:\n",
    "            return f'InnerAutogradTensor({self.elem}, requires_grad=True)'\n",
    "        else:\n",
    "            return f'InnerAutogradTensor({self.elem})'\n",
    "\n",
    "    @classmethod\n",
    "    def __torch_function__(cls, func, types, args, kwargs=None):\n",
    "        print('subclass torch function', func, types)\n",
    "        # return NotImplemented\n",
    "        return super().__torch_function__(func, types, args, kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def __torch_dispatch__(cls, func, types, args=(), kwargs=None):\n",
    "        # We can't handle here because we want to reentrant dispatch *without unwrapping*\n",
    "        #\n",
    "        # If we don't unwrap, then reentrant means we recurse back to here, infinitely!\n",
    "        # If we unwrap, then we are not passing the information to the custom ops.\n",
    "        #\n",
    "        # Hence, the only sensible way is to handle it in the custom op. We could rely on\n",
    "        # custom op's ability to dispatch based on tensor subclass, but it only\n",
    "        # dispatches on a single arg type, which is insufficient for our use case.\n",
    "        #\n",
    "        # Therefore, we do in-house dispatch via TensorSubclassDispatcher. Regardless of input,\n",
    "        # all custom ops will have the same bridging code that dispatches to the same\n",
    "        # TensorSubclassDispatcher.\n",
    "        #\n",
    "        # To avoid registering this same code for all tensor subclasses (and for the default impl\n",
    "        # that could happen with factory functions that do not have tensor args), we\n",
    "        #    1. register the bridging code only for the default impl for each custom op\n",
    "        #    2. here, if `func` is such a custom op, we do\n",
    "        #\n",
    "        #       with enable_reentrant_dispatch(), torch.set_grad_enabled(True):\n",
    "        #           func(*args, **kwargs or {}),\n",
    "        #\n",
    "        #       which will invoke the default impl with our bridging code.\n",
    "        #    3. here, otherwise, we just return NotImplemented as we don't know how to compute norms\n",
    "        #       for ops that are not our custom ops.\n",
    "        print('subclass torch dispatch', func, types, args, kwargs)\n",
    "        # if func in cls.REG and not torch.is_grad_enabled():\n",
    "        #     with torch.set_grad_enabled(True): #, enable_reentrant_dispatch():\n",
    "        #         # return super().__torch_dispatch__(func, types, args, kwargs)\n",
    "        #         return func(*args, **kwargs or {})\n",
    "        return super().__torch_dispatch__(func, types, args, kwargs)\n",
    "        return NotImplemented\n",
    "        kwargs = kwargs or {}\n",
    "        print('subclass dispatch', func, types)\n",
    "        with enable_reentrant_dispatch(), torch.set_grad_enabled(True):\n",
    "            # return func(*args, **kwargs or {})\n",
    "            kwargs = dict(kwargs)\n",
    "            kwargs['requires_grad'] = True\n",
    "            return super().__torch_dispatch__(func, types, args, kwargs)\n",
    "        return NotImplemented\n",
    "        def unwrap(t):\n",
    "            if isinstance(t, cls):\n",
    "                return t.elem\n",
    "            elif isinstance(t, torch.Tensor) and t.requires_grad:\n",
    "                # If any other argument at this level does require gradients\n",
    "                # it will not interact with our inner Tensor and thus this\n",
    "                # should fail.\n",
    "                raise RuntimeError(\"Bad mixup of autograd level\")\n",
    "            else:\n",
    "                return t\n",
    "\n",
    "        def wrap(t):\n",
    "            # Micro-optimization: not necessary to rewrap if the output tensor\n",
    "            # doesn't require gradients\n",
    "            if (\n",
    "                isinstance(t, torch.Tensor)\n",
    "                and not isinstance(t, cls)\n",
    "                and t.requires_grad\n",
    "            ):\n",
    "                return cls(t)\n",
    "            else:\n",
    "                return t\n",
    "\n",
    "        with enable_reentrant_dispatch():\n",
    "            # Override gradient behavior\n",
    "            if func == torch.ops.aten.embedding.default:\n",
    "                args = fill_defaults(args, 5, [-1, False, False])\n",
    "                weight, indices, padding_idx, scale_grad_by_freq, _sparse = map(\n",
    "                    unwrap, args\n",
    "                )\n",
    "                assert not kwargs\n",
    "                # Force sparse gradients.  We could have also done this by\n",
    "                # defining a custom autograd function.\n",
    "                return cls(func(weight, indices, padding_idx, scale_grad_by_freq, True))\n",
    "\n",
    "            return tree_map(\n",
    "                wrap, func(*tree_map(unwrap, args), **tree_map(unwrap, kwargs))\n",
    "            )\n",
    "\n",
    "\n",
    "    # def test_basic(self):\n",
    "    #     x = torch.randn(1, requires_grad=True)\n",
    "    #     y = InnerAutogradTensor(x)\n",
    "    #     self.assertFalse(y.requires_grad)\n",
    "    #     self.assertTrue(y.elem.requires_grad)\n",
    "    #     z = InnerAutogradTensor(x)\n",
    "    #     # Although y and z do not require grad, we are still able\n",
    "    #     # to differentiate\n",
    "    #     r = y + z\n",
    "    #     # Note we have to extract out the inner tensor (which requires_grad)\n",
    "    #     # to actually differentiate\n",
    "    #     r.sum().elem.backward()\n",
    "    #     self.assertEqual(x.grad, torch.tensor([2.0]))  # two uses!\n",
    "\n",
    "    # def test_embedding(self):\n",
    "    #     input = torch.tensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
    "    #     weights = torch.rand(10, 3, requires_grad=True)\n",
    "    #     embedding_matrix = InnerAutogradTensor(weights)\n",
    "    #     r = torch.nn.functional.embedding(input, embedding_matrix)\n",
    "    #     r.sum().elem.backward()\n",
    "    #     # Gradient is sparse even though we didn't ask for it in embedding!\n",
    "    #     self.assertTrue(weights.grad.is_sparse)\n",
    "\n",
    "    # def test_mixing(self):\n",
    "    #     # Mixing behavior is confusing.  Let's take a look\n",
    "    #     w1 = torch.randn(1, requires_grad=True)\n",
    "    #     w2 = torch.randn(1, requires_grad=True)\n",
    "\n",
    "    #     # Autograd doesn't \"unwrap\" variables, they still remember if they\n",
    "    #     # requires_grad; and in fact, inside __torch_dispatch__ it is willing\n",
    "    #     # to mix gradients between multiple levels. The current class does\n",
    "    #     # catch most of these though when it is looking at the different\n",
    "    #     # arguments\n",
    "    #     with self.assertRaisesRegex(RuntimeError, \"Bad mixup of autograd level\"):\n",
    "    #         x = InnerAutogradTensor(w1) + w2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMode(torch.utils._python_dispatch.TorchDispatchMode):\n",
    "    def __torch_dispatch__(self, func, types, args=(), kwargs=None):\n",
    "        print('mode', func, types)\n",
    "        return func(*args, **kwargs or {})\n",
    "\n",
    "torch.library.custom_op\n",
    "\n",
    "def foo_fn(x: InnerAutogradTensor, y: InnerAutogradTensor) -> InnerAutogradTensor:\n",
    "    # 1/0\n",
    "    print('foo', x.elem, y.elem, x.elem + y.elem)\n",
    "    return InnerAutogradTensor(x.elem + y.elem)\n",
    "\n",
    "\n",
    "foo = torch.library.custom_op(\"mylib::foo\", mutates_args={}, schema=\"(Tensor x, Tensor y) -> Tensor\")(foo_fn)\n",
    "\n",
    "\n",
    "# def setup_context(ctx, inputs, output):\n",
    "#     x, y = inputs\n",
    "#     ctx.save_for_backward(x)\n",
    "\n",
    "def backward(ctx, grad):\n",
    "    print('backward', grad)\n",
    "    x, = ctx.saved_tensors\n",
    "    return grad * x.cos()\n",
    "\n",
    "from torch._library.autograd import InfoProtocol\n",
    "from typing import *\n",
    "\n",
    "def make_autograd_impl(op: torch._ops.OpOverload, info: InfoProtocol) -> Callable:\n",
    "    from torch._library import utils\n",
    "    from torch import _C\n",
    "    from dataclasses import dataclass\n",
    "    from torch.utils import _pytree\n",
    "    from torch._library.autograd import supports_tensorlist, not_list_of_tensor\n",
    "\n",
    "    name: str = f\"GeneratedBackwardFor_{op._namespace}_{op._opname}_{op._overloadname}\"\n",
    "\n",
    "    has_kwarg_only_args = utils.has_kwarg_only_args(op._schema)\n",
    "\n",
    "    @dataclass\n",
    "    class Metadata:\n",
    "        keyset: _C.DispatchKeySet\n",
    "        keyword_only_args: Dict[str, Any]\n",
    "\n",
    "    def forward_no_grad(*args):\n",
    "        metadata = args[-1]\n",
    "        args = args[:-1]\n",
    "\n",
    "        with _C._AutoDispatchBelowAutograd():\n",
    "            keyset = metadata.keyset\n",
    "            kwargs = metadata.keyword_only_args\n",
    "            result = op.redispatch(keyset & _C._after_autograd_keyset, *args, **kwargs)\n",
    "            return result\n",
    "\n",
    "    def forward(ctx, *args):\n",
    "        metadata = args[-1]\n",
    "        args = args[:-1]\n",
    "\n",
    "        with _C._AutoDispatchBelowAutograd():\n",
    "            keyset = metadata.keyset\n",
    "            kwargs = metadata.keyword_only_args\n",
    "            result = op.redispatch(keyset & _C._after_autograd_keyset, *args, **kwargs)\n",
    "            if info._setup_context_fn:\n",
    "                # The Dispatcher will remove args that are equal to their default\n",
    "                # values from (args, kwargs). We're going to add it back so that\n",
    "                # the user can access them.\n",
    "                #\n",
    "                # This is OK to do: The Dispatcher removed the args for serialization\n",
    "                # FC/BC reasons (that is, a graph will not store args that are equal\n",
    "                # to their default values), but that doesn't matter here. If the user\n",
    "                # adds a new default arg, then they must update\n",
    "                # their setup_context (along with the rest of their operator\n",
    "                # registrations)\n",
    "                args, kwargs = utils.fill_defaults(op._schema, args, kwargs)\n",
    "\n",
    "                if has_kwarg_only_args:\n",
    "                    info._setup_context_fn(\n",
    "                        ctx=ctx, inputs=args, keyword_only_inputs=kwargs, output=result\n",
    "                    )\n",
    "                else:\n",
    "                    info._setup_context_fn(ctx=ctx, inputs=args, output=result)\n",
    "            return result\n",
    "\n",
    "    def backward(ctx, *grads):\n",
    "        if info._backward_fn:\n",
    "            try:\n",
    "                prev_needs_input_grad = ctx.needs_input_grad\n",
    "                ctx.needs_input_grad = ctx.needs_input_grad[:-1]\n",
    "                result = info._backward_fn(ctx, *grads)\n",
    "            finally:\n",
    "                ctx.needs_input_grad = prev_needs_input_grad\n",
    "            if isinstance(result, tuple):\n",
    "                return (*result, None)\n",
    "            return result, None\n",
    "        raise RuntimeError(\n",
    "            f\"Trying to backward through {op} but no autograd \"\n",
    "            f\"formula was registered. \"\n",
    "            f\"Please use register_autograd to add one.\"\n",
    "        )\n",
    "\n",
    "    Generated = type(\n",
    "        name,\n",
    "        (torch.autograd.Function,),\n",
    "        {\n",
    "            \"forward\": staticmethod(forward),\n",
    "            \"backward\": staticmethod(backward),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    schema = op._schema\n",
    "    if any(\n",
    "        utils.is_tensorlist_like_type(a.type)\n",
    "        for a in (*schema.arguments, *schema.returns)\n",
    "    ):\n",
    "        Generated = supports_tensorlist(Generated)\n",
    "\n",
    "    # The dispatcher passes any keyword-only-args as kwargs and the\n",
    "    # rest of the args (even if specified as kwargs) as args.\n",
    "    def autograd_impl(keyset, *args, **keyword_only_args):\n",
    "        print('autograd_impl', keyset, args, keyword_only_args)\n",
    "        if _C.is_grad_enabled() and _pytree.tree_any_only(\n",
    "            torch.Tensor, lambda x: x.requires_grad, args, not_list_of_tensor\n",
    "        ):\n",
    "            result = Generated.apply(*args, Metadata(keyset, keyword_only_args))  # type: ignore[attr-defined]\n",
    "        else:\n",
    "            result = forward_no_grad(*args, Metadata(keyset, keyword_only_args))\n",
    "        return result\n",
    "\n",
    "    return autograd_impl\n",
    "\n",
    "foo.register_autograd(backward)\n",
    "# foo._lib.impl(foo._name, make_autograd_impl(foo._opoverload, foo), \"Autograd\", with_keyset=True)\n",
    "\n",
    "# @foo.register_torch_dispatch(InnerAutogradTensor)\n",
    "# def _(mode, func, types, args, kwargs):\n",
    "#     print('cop subclass dispatch')\n",
    "#     return func(*args, **kwargs)\n",
    "\n",
    "@torch.library.custom_op(\"mylib::foox\", mutates_args={}, schema=\"() -> Tensor\")\n",
    "def foox() -> InnerAutogradTensor:\n",
    "    return torch.randn(1, requires_grad=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lib = torch.library.Library('mylib29', 'FRAGMENT')\n",
    "lib.define('foo(Tensor x, Tensor y) -> Tensor')\n",
    "\n",
    "def wrap_keyset(fn, desc, pass_keyset=False):\n",
    "    def wrapper(keyset, *args, **kwargs):\n",
    "        print('wrap_keyset', desc, keyset)\n",
    "        if pass_keyset:\n",
    "            return fn(*args, keyset, **kwargs)\n",
    "        else:\n",
    "            return fn(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "lib.impl('foo', wrap_keyset(foo_fn, 'foo'), 'CompositeExplicitAutograd', with_keyset=True)\n",
    "\n",
    "class Foo(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i, j, keyset):\n",
    "        print('autograd', torch.is_grad_enabled(), keyset)\n",
    "        with torch.set_grad_enabled(True):\n",
    "        #     return InnerAutogradTensor(i.elem + j.elem)\n",
    "            return foo_fn(i, j)\n",
    "            return getattr(torch.ops, lib.ns).foo.default.redispatch(\n",
    "                torch._C.DispatchKeySet(torch._C.DispatchKey.CompositeExplicitAutograd),\n",
    "                # keyset & torch._C._after_autograd_keyset,\n",
    "                # torch._C._after_autograd_keyset,\n",
    "                i, j\n",
    "            )\n",
    "        with torch.set_grad_enabled(True):\n",
    "            return InnerAutogradTensor(i.elem + j.elem)\n",
    "        # result = i.exp()\n",
    "        ctx.save_for_backward(result)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return InnerAutogradTensor(grad_output.elem * 0.4), InnerAutogradTensor(grad_output.elem * 0.35), None\n",
    "        result, = ctx.saved_tensors\n",
    "        return grad_output * result\n",
    "\n",
    "\n",
    "lib.impl('foo', wrap_keyset(Foo.apply, 'foo autograd', pass_keyset=True), 'Autograd', with_keyset=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mylib2::foo(Tensor x, Tensor y) -> Tensor"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.mylib2.foo.default._schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function <method 'requires_grad_' of 'torch._C.TensorBase' objects> (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch function <method 'requires_grad_' of 'torch._C.TensorBase' objects> (<class '__main__.InnerAutogradTensor'>,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(1, requires_grad=True)\n",
    "y = InnerAutogradTensor(x).requires_grad_()\n",
    "z = InnerAutogradTensor(x).requires_grad_()\n",
    "# Foo.apply(y, z).elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DispatchKeySet(PreDispatch)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._C.DispatchKeySet(torch._C.DispatchKey.PreDispatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Undefined': <DispatchKey.Undefined: 0>,\n",
       " 'CompositeExplicitAutogradNonFunctional': <DispatchKey.CompositeExplicitAutogradNonFunctional: 149>,\n",
       " 'CompositeExplicitAutograd': <DispatchKey.CompositeExplicitAutograd: 148>,\n",
       " 'CompositeImplicitAutogradNestedTensor': <DispatchKey.CompositeImplicitAutogradNestedTensor: 147>,\n",
       " 'CompositeImplicitAutograd': <DispatchKey.CompositeImplicitAutograd: 145>,\n",
       " 'AutogradNestedTensor': <DispatchKey.AutogradNestedTensor: 24>,\n",
       " 'AutogradOther': <DispatchKey.AutogradOther: 22>,\n",
       " 'Autograd': <DispatchKey.Autograd: 144>,\n",
       " 'Conjugate': <DispatchKey.Conjugate: 18>,\n",
       " 'ZeroTensor': <DispatchKey.ZeroTensor: 20>,\n",
       " 'Negative': <DispatchKey.Negative: 19>,\n",
       " 'BackendSelect': <DispatchKey.BackendSelect: 12>,\n",
       " 'ADInplaceOrView': <DispatchKey.ADInplaceOrView: 21>,\n",
       " 'PythonTLSSnapshot': <DispatchKey.PythonTLSSnapshot: 41>,\n",
       " 'Python': <DispatchKey.Python: 13>,\n",
       " 'FuncTorchDynamicLayerFrontMode': <DispatchKey.FuncTorchDynamicLayerFrontMode: 42>,\n",
       " 'FuncTorchDynamicLayerBackMode': <DispatchKey.FuncTorchDynamicLayerBackMode: 15>,\n",
       " 'FuncTorchBatchedDecomposition': <DispatchKey.FuncTorchBatchedDecomposition: 146>,\n",
       " 'FuncTorchBatched': <DispatchKey.FuncTorchBatched: 34>,\n",
       " 'FuncTorchVmapMode': <DispatchKey.FuncTorchVmapMode: 36>,\n",
       " 'FuncTorchGradWrapper': <DispatchKey.FuncTorchGradWrapper: 39>,\n",
       " 'PythonDispatcher': <DispatchKey.PythonDispatcher: 46>,\n",
       " 'PreDispatch': <DispatchKey.PreDispatch: 45>,\n",
       " 'Functionalize': <DispatchKey.Functionalize: 16>,\n",
       " 'AutocastCPU': <DispatchKey.AutocastCPU: 26>,\n",
       " 'AutocastMPS': <DispatchKey.AutocastMPS: 31>,\n",
       " 'AutocastXPU': <DispatchKey.AutocastXPU: 27>,\n",
       " 'AutocastHPU': <DispatchKey.AutocastHPU: 29>,\n",
       " 'AutocastIPU': <DispatchKey.AutocastIPU: 28>,\n",
       " 'AutocastCUDA': <DispatchKey.AutocastCUDA: 32>,\n",
       " 'AutocastPrivateUse1': <DispatchKey.AutocastPrivateUse1: 33>,\n",
       " 'Dense': <DispatchKey.Dense: 1>,\n",
       " 'StartOfDenseBackends': <DispatchKey.StartOfDenseBackends: 48>,\n",
       " 'CPU': <DispatchKey.CPU: 49>,\n",
       " 'CUDA': <DispatchKey.CUDA: 50>,\n",
       " 'HIP': <DispatchKey.HIP: 51>,\n",
       " 'XLA': <DispatchKey.XLA: 52>,\n",
       " 'MPS': <DispatchKey.MPS: 53>,\n",
       " 'IPU': <DispatchKey.IPU: 54>,\n",
       " 'XPU': <DispatchKey.XPU: 55>,\n",
       " 'HPU': <DispatchKey.HPU: 56>,\n",
       " 'VE': <DispatchKey.VE: 57>,\n",
       " 'Lazy': <DispatchKey.Lazy: 58>,\n",
       " 'MTIA': <DispatchKey.MTIA: 59>,\n",
       " 'PrivateUse1': <DispatchKey.PrivateUse1: 60>,\n",
       " 'PrivateUse2': <DispatchKey.PrivateUse2: 61>,\n",
       " 'PrivateUse3': <DispatchKey.PrivateUse3: 62>,\n",
       " 'Meta': <DispatchKey.Meta: 63>,\n",
       " 'EndOfDenseBackends': <DispatchKey.Meta: 63>,\n",
       " 'Quantized': <DispatchKey.Quantized: 6>,\n",
       " 'StartOfQuantizedBackends': <DispatchKey.StartOfQuantizedBackends: 64>,\n",
       " 'QuantizedCPU': <DispatchKey.QuantizedCPU: 65>,\n",
       " 'QuantizedCUDA': <DispatchKey.QuantizedCUDA: 66>,\n",
       " 'QuantizedHIP': <DispatchKey.QuantizedHIP: 67>,\n",
       " 'QuantizedXLA': <DispatchKey.QuantizedXLA: 68>,\n",
       " 'QuantizedMPS': <DispatchKey.QuantizedMPS: 69>,\n",
       " 'QuantizedIPU': <DispatchKey.QuantizedIPU: 70>,\n",
       " 'QuantizedXPU': <DispatchKey.QuantizedXPU: 71>,\n",
       " 'QuantizedHPU': <DispatchKey.QuantizedHPU: 72>,\n",
       " 'QuantizedVE': <DispatchKey.QuantizedVE: 73>,\n",
       " 'QuantizedLazy': <DispatchKey.QuantizedLazy: 74>,\n",
       " 'QuantizedMTIA': <DispatchKey.QuantizedMTIA: 75>,\n",
       " 'QuantizedPrivateUse1': <DispatchKey.QuantizedPrivateUse1: 76>,\n",
       " 'QuantizedPrivateUse2': <DispatchKey.QuantizedPrivateUse2: 77>,\n",
       " 'QuantizedPrivateUse3': <DispatchKey.QuantizedPrivateUse3: 78>,\n",
       " 'QuantizedMeta': <DispatchKey.QuantizedMeta: 79>,\n",
       " 'EndOfQuantizedBackends': <DispatchKey.QuantizedMeta: 79>,\n",
       " 'Sparse': <DispatchKey.Sparse: 9>,\n",
       " 'StartOfSparseBackends': <DispatchKey.StartOfSparseBackends: 80>,\n",
       " 'SparseCPU': <DispatchKey.SparseCPU: 81>,\n",
       " 'SparseCUDA': <DispatchKey.SparseCUDA: 82>,\n",
       " 'SparseHIP': <DispatchKey.SparseHIP: 83>,\n",
       " 'SparseXLA': <DispatchKey.SparseXLA: 84>,\n",
       " 'SparseMPS': <DispatchKey.SparseMPS: 85>,\n",
       " 'SparseIPU': <DispatchKey.SparseIPU: 86>,\n",
       " 'SparseXPU': <DispatchKey.SparseXPU: 87>,\n",
       " 'SparseHPU': <DispatchKey.SparseHPU: 88>,\n",
       " 'SparseVE': <DispatchKey.SparseVE: 89>,\n",
       " 'SparseLazy': <DispatchKey.SparseLazy: 90>,\n",
       " 'SparseMTIA': <DispatchKey.SparseMTIA: 91>,\n",
       " 'SparsePrivateUse1': <DispatchKey.SparsePrivateUse1: 92>,\n",
       " 'SparsePrivateUse2': <DispatchKey.SparsePrivateUse2: 93>,\n",
       " 'SparsePrivateUse3': <DispatchKey.SparsePrivateUse3: 94>,\n",
       " 'SparseMeta': <DispatchKey.SparseMeta: 95>,\n",
       " 'EndOfSparseBackends': <DispatchKey.SparseMeta: 95>,\n",
       " 'SparseCsr': <DispatchKey.SparseCsr: 10>,\n",
       " 'StartOfSparseCsrBackends': <DispatchKey.StartOfSparseCsrBackends: 96>,\n",
       " 'SparseCsrCPU': <DispatchKey.SparseCsrCPU: 97>,\n",
       " 'SparseCsrCUDA': <DispatchKey.SparseCsrCUDA: 98>,\n",
       " 'SparseCsrHIP': <DispatchKey.SparseCsrHIP: 99>,\n",
       " 'SparseCsrXLA': <DispatchKey.SparseCsrXLA: 100>,\n",
       " 'SparseCsrMPS': <DispatchKey.SparseCsrMPS: 101>,\n",
       " 'SparseCsrIPU': <DispatchKey.SparseCsrIPU: 102>,\n",
       " 'SparseCsrXPU': <DispatchKey.SparseCsrXPU: 103>,\n",
       " 'SparseCsrHPU': <DispatchKey.SparseCsrHPU: 104>,\n",
       " 'SparseCsrVE': <DispatchKey.SparseCsrVE: 105>,\n",
       " 'SparseCsrLazy': <DispatchKey.SparseCsrLazy: 106>,\n",
       " 'SparseCsrMTIA': <DispatchKey.SparseCsrMTIA: 107>,\n",
       " 'SparseCsrPrivateUse1': <DispatchKey.SparseCsrPrivateUse1: 108>,\n",
       " 'SparseCsrPrivateUse2': <DispatchKey.SparseCsrPrivateUse2: 109>,\n",
       " 'SparseCsrPrivateUse3': <DispatchKey.SparseCsrPrivateUse3: 110>,\n",
       " 'SparseCsrMeta': <DispatchKey.SparseCsrMeta: 111>,\n",
       " 'EndOfSparseCsrBackends': <DispatchKey.SparseCsrMeta: 111>,\n",
       " 'NestedTensor': <DispatchKey.NestedTensor: 11>,\n",
       " 'StartOfNestedTensorBackends': <DispatchKey.StartOfNestedTensorBackends: 112>,\n",
       " 'NestedTensorCPU': <DispatchKey.NestedTensorCPU: 113>,\n",
       " 'NestedTensorCUDA': <DispatchKey.NestedTensorCUDA: 114>,\n",
       " 'NestedTensorHIP': <DispatchKey.NestedTensorHIP: 115>,\n",
       " 'NestedTensorXLA': <DispatchKey.NestedTensorXLA: 116>,\n",
       " 'NestedTensorMPS': <DispatchKey.NestedTensorMPS: 117>,\n",
       " 'NestedTensorIPU': <DispatchKey.NestedTensorIPU: 118>,\n",
       " 'NestedTensorXPU': <DispatchKey.NestedTensorXPU: 119>,\n",
       " 'NestedTensorHPU': <DispatchKey.NestedTensorHPU: 120>,\n",
       " 'NestedTensorVE': <DispatchKey.NestedTensorVE: 121>,\n",
       " 'NestedTensorLazy': <DispatchKey.NestedTensorLazy: 122>,\n",
       " 'NestedTensorMTIA': <DispatchKey.NestedTensorMTIA: 123>,\n",
       " 'NestedTensorPrivateUse1': <DispatchKey.NestedTensorPrivateUse1: 124>,\n",
       " 'NestedTensorPrivateUse2': <DispatchKey.NestedTensorPrivateUse2: 125>,\n",
       " 'NestedTensorPrivateUse3': <DispatchKey.NestedTensorPrivateUse3: 126>,\n",
       " 'NestedTensorMeta': <DispatchKey.NestedTensorMeta: 127>,\n",
       " 'EndOfNestedTensorBackends': <DispatchKey.NestedTensorMeta: 127>,\n",
       " 'AutogradFunctionality': <DispatchKey.AutogradFunctionality: 23>,\n",
       " 'StartOfAutogradFunctionalityBackends': <DispatchKey.StartOfAutogradFunctionalityBackends: 128>,\n",
       " 'AutogradCPU': <DispatchKey.AutogradCPU: 129>,\n",
       " 'AutogradCUDA': <DispatchKey.AutogradCUDA: 130>,\n",
       " 'AutogradHIP': <DispatchKey.AutogradHIP: 131>,\n",
       " 'AutogradXLA': <DispatchKey.AutogradXLA: 132>,\n",
       " 'AutogradMPS': <DispatchKey.AutogradMPS: 133>,\n",
       " 'AutogradIPU': <DispatchKey.AutogradIPU: 134>,\n",
       " 'AutogradXPU': <DispatchKey.AutogradXPU: 135>,\n",
       " 'AutogradHPU': <DispatchKey.AutogradHPU: 136>,\n",
       " 'AutogradVE': <DispatchKey.AutogradVE: 137>,\n",
       " 'AutogradLazy': <DispatchKey.AutogradLazy: 138>,\n",
       " 'AutogradMTIA': <DispatchKey.AutogradMTIA: 139>,\n",
       " 'AutogradPrivateUse1': <DispatchKey.AutogradPrivateUse1: 140>,\n",
       " 'AutogradPrivateUse2': <DispatchKey.AutogradPrivateUse2: 141>,\n",
       " 'AutogradPrivateUse3': <DispatchKey.AutogradPrivateUse3: 142>,\n",
       " 'AutogradMeta': <DispatchKey.AutogradMeta: 143>,\n",
       " 'EndOfAutogradFunctionalityBackends': <DispatchKey.AutogradMeta: 143>}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._C.DispatchKey.__members__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo tensor([1.6930], requires_grad=True) tensor([1.6930], requires_grad=True) tensor([3.3860], grad_fn=<AddBackward0>)\n",
      "subclass torch function <method-wrapper '__get__' of getset_descriptor object at 0x121328840> (<class '__main__.InnerAutogradTensor'>,)\n",
      "tensor([3.3860], grad_fn=<AddBackward0>) None\n"
     ]
    }
   ],
   "source": [
    "out = torch.ops.mylib15.foo.default.redispatch(\n",
    "    torch._C.DispatchKeySet(torch._C.DispatchKey.CompositeExplicitAutograd),\n",
    "    # torch._C._after_autograd_keyset,\n",
    "    y, z\n",
    ")\n",
    "print(out.elem, out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrap_keyset foo DispatchKeySet(CPU)\n",
      "foo tensor([1.6930], requires_grad=True) tensor([1.6930], requires_grad=True) tensor([3.3860])\n",
      "subclass torch function <method-wrapper '__get__' of getset_descriptor object at 0x121328840> (<class '__main__.InnerAutogradTensor'>,)\n",
      "tensor([3.3860]) None\n"
     ]
    }
   ],
   "source": [
    "with torch._C._AutoDispatchBelowAutograd():\n",
    "    out = torch.ops.mylib18.foo.default.redispatch(\n",
    "        (\n",
    "            torch._C.DispatchKeySet(torch._C.DispatchKey.CPU)\n",
    "        ),\n",
    "        y, z\n",
    "    )\n",
    "print(out.elem, out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrap_keyset foo autograd DispatchKeySet(CPU, Python, AutogradCPU)\n",
      "autograd False\n",
      "wrap_keyset foo DispatchKeySet()\n",
      "foo tensor([1.6930], requires_grad=True) tensor([1.6930], requires_grad=True) tensor([3.3860])\n",
      "subclass torch function <method-wrapper '__get__' of getset_descriptor object at 0x121328840> (<class '__main__.InnerAutogradTensor'>,)\n",
      "tensor([3.3860]) <torch.autograd.function.FooBackward object at 0x31aed0750>\n"
     ]
    }
   ],
   "source": [
    "with torch._C._AutoDispatchBelowAutograd():\n",
    "    out = torch.ops.mylib18.foo.default.redispatch((\n",
    "        torch._C.DispatchKeySet(torch._C.DispatchKey.CPU)\n",
    "        |\n",
    "        torch._C.DispatchKeySet(torch._C.DispatchKey.Python)\n",
    "        |\n",
    "        torch._C.DispatchKeySet(torch._C.DispatchKey.AutogradCPU)\n",
    "    ) & torch._C._after_autograd_keyset,\n",
    "    y, z\n",
    "    )\n",
    "print(out.elem, out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function mylib29.foo.default (<class '__main__.InnerAutogradTensor'>,)\n",
      "wrap_keyset foo autograd DispatchKeySet(CPU, Python, AutogradCPU)\n",
      "autograd False DispatchKeySet(CPU, Python, AutogradCPU)\n",
      "foo tensor([0.1011], requires_grad=True) tensor([0.1011], requires_grad=True) tensor([0.2021], grad_fn=<AddBackward0>)\n",
      "subclass torch function <method-wrapper '__get__' of getset_descriptor object at 0x10422c500> (<class '__main__.InnerAutogradTensor'>,)\n",
      "tensor([0.2021], grad_fn=<AddBackward0>) <torch.autograd.function.FooBackward object at 0x16d701950>\n"
     ]
    }
   ],
   "source": [
    "out = getattr(torch.ops, lib.ns).foo.default(y, z)\n",
    "print(out.elem, out.grad_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function <function grad at 0x123543240> (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch function <method-wrapper '__set__' of getset_descriptor object at 0x10422c7c0> (<class '__main__.InnerAutogradTensor'>,)\n"
     ]
    }
   ],
   "source": [
    "y.grad = torch.autograd.grad(out, y, grad_outputs=InnerAutogradTensor(torch.tensor([1.])))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function <method-wrapper '__get__' of getset_descriptor object at 0x10422c7c0> (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch function <method-wrapper '__get__' of getset_descriptor object at 0x10422c980> (<class '__main__.InnerAutogradTensor'>,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InnerAutogradTensor(tensor([0.4000]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "out.backward(InnerAutogradTensor(torch.tensor([1.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DispatchKeySet(CPU, CUDA, HIP, XLA, MPS, IPU, XPU, HPU, VE, Lazy, MTIA, PrivateUse1, PrivateUse2, PrivateUse3, Meta, FPGA, MAIA, Vulkan, Metal, QuantizedCPU, QuantizedCUDA, QuantizedHIP, QuantizedXLA, QuantizedMPS, QuantizedIPU, QuantizedXPU, QuantizedHPU, QuantizedVE, QuantizedLazy, QuantizedMTIA, QuantizedPrivateUse1, QuantizedPrivateUse2, QuantizedPrivateUse3, QuantizedMeta, CustomRNGKeyId, MkldnnCPU, SparseCPU, SparseCUDA, SparseHIP, SparseXLA, SparseMPS, SparseIPU, SparseXPU, SparseHPU, SparseVE, SparseLazy, SparseMTIA, SparsePrivateUse1, SparsePrivateUse2, SparsePrivateUse3, SparseMeta, SparseCsrCPU, SparseCsrCUDA, SparseCsrHIP, SparseCsrXLA, SparseCsrMPS, SparseCsrIPU, SparseCsrXPU, SparseCsrHPU, SparseCsrVE, SparseCsrLazy, SparseCsrMTIA, SparseCsrPrivateUse1, SparseCsrPrivateUse2, SparseCsrPrivateUse3, SparseCsrMeta, NestedTensorCPU, NestedTensorCUDA, NestedTensorHIP, NestedTensorXLA, NestedTensorMPS, NestedTensorIPU, NestedTensorXPU, NestedTensorHPU, NestedTensorVE, NestedTensorLazy, NestedTensorMTIA, NestedTensorPrivateUse1, NestedTensorPrivateUse2, NestedTensorPrivateUse3, NestedTensorMeta, BackendSelect, Python, Fake, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, PythonDispatcher)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._C._after_autograd_keyset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function <method 'untyped_storage' of 'torch._C.TensorBase' objects> (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch function <method 'untyped_storage' of 'torch._C.TensorBase' objects> (<class '__main__.InnerAutogradTensor'>,)\n",
      "foo tensor([1.6930], requires_grad=True) tensor([1.6930], requires_grad=True) tensor([3.3860], grad_fn=<AddBackward0>)\n",
      "subclass torch function <method 'untyped_storage' of 'torch._C.TensorBase' objects> (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch function <method 'untyped_storage' of 'torch._C.TensorBase' objects> (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch function <method-wrapper '__get__' of getset_descriptor object at 0x121328840> (<class '__main__.InnerAutogradTensor'>,)\n",
      "tensor([3.3860], grad_fn=<AddBackward0>) None\n"
     ]
    }
   ],
   "source": [
    "out = torch.ops.mylib.foo.default.redispatch(\n",
    "    torch._C.DispatchKeySet(torch._C.DispatchKey.CompositeExplicitAutograd),\n",
    "    # torch._C._after_autograd_keyset,\n",
    "    y, z\n",
    ")\n",
    "print(out.elem, out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function mylib.foo.default (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch dispatch mylib.foo.default (<class '__main__.InnerAutogradTensor'>,) False False\n",
      "foo tensor([1.6930], requires_grad=True) tensor([1.6930], requires_grad=True) tensor([3.3860])\n",
      "subclass torch function <method-wrapper '__get__' of getset_descriptor object at 0x121328840> (<class '__main__.InnerAutogradTensor'>,)\n",
      "tensor([3.3860]) <torch.autograd.function.GeneratedBackwardFor_mylib_foo_defaultBackward object at 0x31aba0c50>\n"
     ]
    }
   ],
   "source": [
    "out = torch.ops.mylib.foo.default._op_dk(\n",
    "    torch._C.DispatchKey.Undefined,\n",
    "    # 'a',\n",
    "    # torch._C._after_autograd_keyset,\n",
    "    y, z\n",
    ")\n",
    "print(out.elem, out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<DispatchKey.CompositeExplicitAutograd: 148>: <DispatchKey.CompositeExplicitAutograd: 148>,\n",
       " <DispatchKey.Autograd: 144>: <DispatchKey.Autograd: 144>,\n",
       " <DispatchKey.Python: 13>: <DispatchKey.Python: 13>}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.mylib.foo.default._dispatch_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mylib/foo/Autograd', 'mylib/foo/CompositeExplicitAutograd'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo._lib._op_impls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function mylib.foo.default (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch dispatch mylib.foo.default (<class '__main__.InnerAutogradTensor'>,) False False\n",
      "foo tensor([0.2494], requires_grad=True) tensor([0.2494], requires_grad=True) tensor([0.4988])\n",
      "subclass torch function <method-wrapper '__get__' of getset_descriptor object at 0x121328840> (<class '__main__.InnerAutogradTensor'>,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.function.GeneratedBackwardFor_mylib_foo_defaultBackward at 0x31a6d8550>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.mylib.foo.default(y, z).grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/library.py:323: UserWarning: Warning only once for all operators,  other operators may also be overridden.\n",
      "  Overriding a previously registered kernel for the same operator and the same dispatch key\n",
      "  operator: mylib::foo(Tensor x, Tensor y) -> Tensor\n",
      "    registered at /dev/null:185\n",
      "  dispatch key: Autograd\n",
      "  previous kernel: no debug info\n",
      "       new kernel: registered at /dev/null:185 (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729647038473/work/aten/src/ATen/core/dispatch/OperatorEntry.cpp:162.)\n",
      "  self.m.impl(\n"
     ]
    }
   ],
   "source": [
    "foo._lib.impl(foo._name, foo, \"Autograd\", with_keyset=True)\n",
    "# torch.ops.mylib.foo.default._op_dk(torch._C.DispatchKey.Autograd, y, z).elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function mylib.foo.default (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch dispatch mylib.foo.default (<class '__main__.InnerAutogradTensor'>,) False False\n",
      "foo tensor([-2.5916], requires_grad=True) tensor([-2.5916], requires_grad=True) tensor([-5.1833])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-5.1833])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.mylib.foo.default._op_dk(torch._C.DispatchKey.Autograd, y, z).elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function <method 'requires_grad_' of 'torch._C.TensorBase' objects> (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch function <method 'requires_grad_' of 'torch._C.TensorBase' objects> (<class '__main__.InnerAutogradTensor'>,)\n"
     ]
    }
   ],
   "source": [
    "InnerAutogradTensor.REG.clear()\n",
    "# InnerAutogradTensor.REG[torch.ops.mylib.foo.default] = foo\n",
    "x = torch.randn(1, requires_grad=True)\n",
    "y = InnerAutogradTensor(x).requires_grad_()\n",
    "z = InnerAutogradTensor(x).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass torch function mylib.foo (<class '__main__.InnerAutogradTensor'>,)\n",
      "subclass torch dispatch mylib.foo.default (<class '__main__.InnerAutogradTensor'>,) False False\n",
      "foo tensor([-2.5916], requires_grad=True) tensor([-2.5916], requires_grad=True) tensor([-5.1833])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-5.1833])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.mylib.foo(y, z).elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass dispatch aten.add.Tensor (<class '__main__.InnerAutogradTensor'>,) False True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'elem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[203], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m r \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m z\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Note we have to extract out the inner tensor (which requires_grad)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# to actually differentiate\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m r\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39melem\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'elem'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Although y and z do not require grad, we are still able\n",
    "# to differentiate\n",
    "r = y + z\n",
    "# Note we have to extract out the inner tensor (which requires_grad)\n",
    "# to actually differentiate\n",
    "r.sum().elem.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OpOverload.redispatch() missing 1 required positional argument: 'keyset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39mlinear\u001b[38;5;241m.\u001b[39mdefault\u001b[38;5;241m.\u001b[39mredispatch()\n",
      "\u001b[0;31mTypeError\u001b[0m: OpOverload.redispatch() missing 1 required positional argument: 'keyset'"
     ]
    }
   ],
   "source": [
    "torch.ops.aten.linear.default.redispatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we manually compute, it should be $1 * \\frac{1}{\\sqrt{2}} * 1  * \\frac{1}{\\sqrt{2}} * 1 + 1 = 1.5$. So yay!\n",
    "\n",
    "Note that we get norm type and dim propagation too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex2: build modula norm automatically for regular PyTorch modules\n",
    "\n",
    "To compute the modula norm, we need to get the local \"influence\" of weight norms to output. Fortunately, we can use PyTorch autograd!\n",
    "\n",
    "Let's first specify that the weight norm sizes require gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normed_state_dict:\n",
      "{'net.0.bias': RMS_NormTensor(norm_size=tensor(0., requires_grad=True), elem_dims=(-1,), ...),\n",
      " 'net.0.weight': RMS_RMS_NormTensor(norm_size=tensor(1., requires_grad=True), elem_dims=(-1, -2), ...),\n",
      " 'net.2.bias': RMS_NormTensor(norm_size=tensor(0., requires_grad=True), elem_dims=(-1,), ...),\n",
      " 'net.2.weight': RMS_RMS_NormTensor(norm_size=tensor(1., requires_grad=True), elem_dims=(-1, -2), ...),\n",
      " 'net.4.bias': RMS_NormTensor(norm_size=tensor(0., requires_grad=True), elem_dims=(-1,), ...),\n",
      " 'net.4.weight': RMS_RMS_NormTensor(norm_size=tensor(1., requires_grad=True), elem_dims=(-1, -2), ...)}\n"
     ]
    }
   ],
   "source": [
    "normed_state_dict = {k: v.norm_size_requires_grad_(True) for k, v in normed_state_dict.items()}\n",
    "print('normed_state_dict:')\n",
    "from pprint import pprint\n",
    "pprint(normed_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "output_norm: \n",
      " RMS_NormTensor(\n",
      "    norm_size=tensor(1.5000, grad_fn=<AddBackward0>),\n",
      "    elem_dims=(1,),\n",
      "    unwrapped=FakeTensor(..., size=(10, 8)),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "output_norm = norm_map(normed_input, normed_state_dict=normed_state_dict)\n",
    "print('output_norm: \\n', output_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `grad_fn`! Now invoke autograd..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpOverload(op='aten.linear', overload='default')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.aten.linear.default.overloadpacket.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_dir',\n",
       " 'name',\n",
       " 'op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152',\n",
       " 'op__wrapper__torch__C__nn_linear__4713105744',\n",
       " 'op__wrapper__torch__C__nn_scaled_dot_product_attention__4713108864',\n",
       " 'op__wrapper__torch__ops_aten_aten_add_Tensor__6134135248',\n",
       " 'op__wrapper__torch__ops_aten_aten_randn__6142561744',\n",
       " 'op__wrapper__torch__ops_aten_aten_relu__6143355280',\n",
       " 'op__wrapper__torch_nn_functional_layer_norm__4765698144']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.ops.auto_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1,), ...), None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from auto_norm.normed_mode_dispatch import normed_mode_propagate\n",
    "from auto_norm.reg_fake_norm_op_registry import REG_FAKE_NORM_OP_REGISTRY\n",
    "\n",
    "# with normed_mode_propagate():\n",
    "x, w, b = (\n",
    "    normed_input,\n",
    "    normed_state_dict['net.0.weight'],\n",
    "    normed_state_dict['net.0.bias'],\n",
    ")\n",
    "x = x.finalize(torch.empty(10, 8)).requires_grad_()\n",
    "w = w.finalize(torch.empty(16, 8)).requires_grad_()\n",
    "b = b.finalize(torch.empty(16)).requires_grad_()\n",
    "op = REG_FAKE_NORM_OP_REGISTRY[torch.nn.functional.linear]\n",
    "y = op.normed_dispatcher(x, w, b)\n",
    "y, y.grad_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REG_FAKE_NORM_OP_LOOKUP_VIA_CUSTOM_OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_norm.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_norm\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "output_norm.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_norm.norm_size.backward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mudula norm, we have \n",
    "\n",
    "$$||\\{W_i\\}_i||_\\mathsf{M} := \\max_i  \\frac{\\textsf{total\\_mass}}{\\textsf{mass}_i} \\textsf{influence}_i ||W_i||, $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\textsf{influences}_i = \\frac{\\partial\\ \\textsf{out\\_norm}}{\\partial ||W_i||} $$\n",
    "\n",
    "(If you have read the original modula paper, then for atomic module $\\mathsf{M}$, we assume $\\mathsf{M.norm}(W) := \\alpha ||W||$, for some norm choice $||\\cdot||$ and some scalar $\\alpha$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "influences of net.2.weight:\n",
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "influences = {k: v.norm_size.grad for k, v in normed_state_dict.items()}\n",
    "print('influences of net.2.weight:')\n",
    "print(influences['net.2.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masses:\n",
      "{'net.0.bias': 0.1,\n",
      " 'net.0.weight': 1,\n",
      " 'net.2.bias': 0.1,\n",
      " 'net.2.weight': 1,\n",
      " 'net.4.bias': 0.1,\n",
      " 'net.4.weight': 1}\n",
      "total_mass: 3.3\n"
     ]
    }
   ],
   "source": [
    "masses = {k: 1 if k.endswith('weight') else 0.1 for k in normed_state_dict}\n",
    "print('masses:')\n",
    "pprint(masses)\n",
    "\n",
    "total_mass = sum(masses.values())\n",
    "print(f'total_mass: {total_mass:g}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modula_norm: 1.6500\n"
     ]
    }
   ],
   "source": [
    "modula_norm = max(\n",
    "    total_mass / masses[k] * influences[k] * normed_state_dict[k].norm_size.detach()\n",
    "    for k in normed_state_dict\n",
    ")\n",
    "print(f'modula_norm: {modula_norm:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex3: Optimize scaling factors\n",
    "\n",
    "Here the output norm is 1.5, not unit norm. How can we scale the layers so that it becomes unit norm?\n",
    "\n",
    "Let's use the special class `auto_norm.ConstantScaler` to optimize for scaling factors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching profiler._record_function_enter_new, (), ('_compile.compile_inner (dynamo_timed)', None), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (False,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty of type object at 0x10f32c008>, (), (111,), {'dtype': torch.float32, 'device': device(type='cpu')}\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'element_size' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'as_strided_' of 'torch._C.TensorBase' objects>, (), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), torch.Size([10, 8]), (8, 1), 0), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'copy_' of 'torch._C.TensorBase' objects>, (), (tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]])), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]]), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), ((10, 8), (8, 1)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (False,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty of type object at 0x10f32c008>, (), (32,), {'dtype': torch.float32, 'device': device(type='cpu')}\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'element_size' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'as_strided_' of 'torch._C.TensorBase' objects>, (), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), torch.Size([]), (), 0), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'copy_' of 'torch._C.TensorBase' objects>, (), (tensor(0.), tensor(1.)), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (tensor(1.), False), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), ((), ()), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True), FakeTensor(..., size=())), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28d80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]]),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([16, 8]), (8, 1)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8)),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28d80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609]),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([16]), (1,)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)), True), None\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FakeTensor(..., size=(10, 8), requires_grad=True), Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)), Parameter(FakeTensor(..., size=(16,), requires_grad=True))), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (False,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty of type object at 0x10f32c008>, (), (32,), {'dtype': torch.float32, 'device': device(type='cpu')}\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'element_size' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'as_strided_' of 'torch._C.TensorBase' objects>, (), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), torch.Size([]), (), 0), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'copy_' of 'torch._C.TensorBase' objects>, (), (tensor(0.), tensor(1.)), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (tensor(1.), False), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), ((), ()), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>), FakeTensor(..., size=())), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <function relu at 0x11c0df600>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'inplace': False}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28d80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]]),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([16, 16]), (16, 1)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16)),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28d80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832]),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([16]), (1,)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)), True), None\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>), Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)), Parameter(FakeTensor(..., size=(16,), requires_grad=True))), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (False,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty of type object at 0x10f32c008>, (), (32,), {'dtype': torch.float32, 'device': device(type='cpu')}\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'element_size' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'as_strided_' of 'torch._C.TensorBase' objects>, (), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), torch.Size([]), (), 0), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'copy_' of 'torch._C.TensorBase' objects>, (), (tensor(0.), tensor(1.)), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (tensor(1.), False), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), ((), ()), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>), FakeTensor(..., size=())), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <function relu at 0x11c0df600>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'inplace': False}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28d80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]]),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([8, 16]), (16, 1)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16)),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28d80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924]),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([8]), (1,)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,)),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,)), True), None\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>), Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)), Parameter(FakeTensor(..., size=(8,), requires_grad=True))), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (False,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty of type object at 0x10f32c008>, (), (32,), {'dtype': torch.float32, 'device': device(type='cpu')}\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]),), None\n",
      "ExportFakeFunctionMode dispatching <method 'element_size' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'as_strided_' of 'torch._C.TensorBase' objects>, (), (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), torch.Size([]), (), 0), None\n",
      "ExportFakeFunctionMode dispatching <method 'clone' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'copy_' of 'torch._C.TensorBase' objects>, (), (tensor(0.), tensor(1.)), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'requires_grad_' of 'torch._C.TensorBase' objects>, (), (tensor(1.), False), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor(1.),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), ((), ()), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>), FakeTensor(..., size=())), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method 'add' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>), FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>)), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29900>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), {'memory_format': torch.preserve_format}\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching profiler._record_function_enter_new, (), ('OutputGraph.call_user_compiler (dynamo_timed)', None), {}\n",
      "ExportFakeFunctionMode dispatching profiler._record_function_exit._RecordFunction, (), (<torch.ScriptObject object at 0x311156650>,), {}\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([[-0.5987, -1.4379, -0.0727,  0.7559,  0.5247,  0.2773, -0.1642,  1.4604],\n",
      "        [ 0.5857, -0.0591, -0.2283,  0.2118, -0.0901, -0.4193, -1.3814,  0.7365],\n",
      "        [-0.2951,  1.5737, -1.6958, -2.6760, -1.4862, -1.0574,  2.0471, -0.1784],\n",
      "        [ 0.8522,  0.3332, -1.3924, -2.4705, -0.3980,  1.2932,  0.8630,  0.7114],\n",
      "        [ 0.5178, -0.8385, -1.1924,  0.2043, -1.0558, -1.9803, -0.8809,  0.4878],\n",
      "        [ 1.2046,  1.1006,  1.3434, -1.2230,  0.2825, -1.0586, -0.7185, -0.8391],\n",
      "        [-0.4893,  0.5534, -0.2063,  1.6485,  0.6543, -0.0716, -0.7954, -0.2680],\n",
      "        [ 0.7354, -0.6773,  0.1088, -0.6905, -1.2562, -0.5258,  0.1183,  1.5214],\n",
      "        [ 0.6987,  0.2470, -0.6693,  0.3906, -0.4304,  0.2741, -0.6133,  1.1662],\n",
      "        [-0.0221, -0.7958,  1.3911,  1.2474,  0.5356,  2.9735, -0.3995,  0.8350]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching profiler._record_function_exit._RecordFunction, (), (<torch.ScriptObject object at 0x1017c6e70>,), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2936,  0.1380, -0.1798,  0.2952,  0.2764, -0.1115, -0.3328,  0.1098],\n",
      "        [ 0.0121,  0.2633, -0.0200, -0.0457, -0.0269, -0.3286,  0.1189, -0.0321],\n",
      "        [ 0.1231,  0.0573, -0.3488, -0.3195, -0.0338, -0.0694,  0.1376, -0.0894],\n",
      "        [-0.1848,  0.3135,  0.0932,  0.2759,  0.2422, -0.2357, -0.0874, -0.0652],\n",
      "        [-0.0710, -0.2144, -0.1860, -0.2484,  0.1595, -0.0609, -0.2684,  0.0875],\n",
      "        [ 0.2971,  0.0053, -0.2612, -0.0655,  0.2984,  0.2525,  0.0500,  0.1594],\n",
      "        [-0.1699,  0.3485,  0.1975,  0.3072, -0.3416,  0.2928,  0.2596, -0.0581],\n",
      "        [-0.1855, -0.0410,  0.0109, -0.0037,  0.1713,  0.1809,  0.3328, -0.0628],\n",
      "        [ 0.0794,  0.2706,  0.0779,  0.1895, -0.1270, -0.0868,  0.3110,  0.1419],\n",
      "        [-0.1938,  0.2125,  0.2388,  0.0511, -0.0114, -0.2986, -0.0821,  0.2851],\n",
      "        [-0.3105, -0.2411, -0.1005,  0.3134,  0.3175, -0.2429,  0.0333,  0.1199],\n",
      "        [-0.1084, -0.1360,  0.3226, -0.1335, -0.1506, -0.0734, -0.3465,  0.0774],\n",
      "        [-0.1775, -0.1746, -0.1186, -0.2558,  0.3250, -0.0373, -0.0250,  0.2770],\n",
      "        [ 0.3433, -0.0045,  0.2411,  0.3129, -0.3472, -0.0831, -0.0887, -0.1399],\n",
      "        [-0.0291,  0.1877, -0.1952,  0.1327,  0.2525, -0.1568,  0.3111,  0.2847],\n",
      "        [ 0.1936, -0.2282, -0.2200,  0.1417,  0.1348,  0.2196, -0.1087, -0.2468]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([16, 8]), (8, 1)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([-0.2411, -0.2384, -0.1283, -0.0332,  0.3318, -0.1013, -0.1229,  0.2371,\n",
      "        -0.3340,  0.2321,  0.1452,  0.1129, -0.1036,  0.2828, -0.0297,  0.1609],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([16]), (1,)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[-0.1018, -0.2086, -0.1819,  0.1263,  0.0410, -0.1310,  0.2350, -0.0299,\n",
      "         -0.1899,  0.0079, -0.1347,  0.1193,  0.1313, -0.0315, -0.1860, -0.2162],\n",
      "        [-0.2147, -0.0909, -0.0039,  0.0738, -0.1059, -0.2379,  0.1401,  0.0594,\n",
      "          0.0565,  0.0787,  0.2421, -0.1460,  0.0037,  0.1648,  0.0524, -0.1046],\n",
      "        [-0.0179, -0.1308,  0.0817, -0.1148,  0.1811,  0.0727, -0.0177,  0.1510,\n",
      "         -0.0633,  0.0341,  0.0136,  0.1202, -0.2063, -0.1561, -0.1719,  0.0455],\n",
      "        [ 0.1557,  0.1292,  0.1561,  0.1683, -0.0357,  0.2459, -0.0714,  0.0616,\n",
      "         -0.0250, -0.1629,  0.1193,  0.1737,  0.0708, -0.0334,  0.1942, -0.1282],\n",
      "        [-0.1459, -0.0410, -0.0788,  0.1644, -0.0699,  0.1275, -0.0889,  0.2148,\n",
      "          0.0261, -0.1990, -0.2030, -0.0885, -0.2309,  0.0868,  0.1390,  0.2334],\n",
      "        [-0.0594, -0.1715, -0.1089, -0.1366, -0.0087,  0.2400,  0.1167, -0.2485,\n",
      "         -0.1708, -0.0869,  0.1361, -0.0470, -0.1318,  0.0892,  0.0133,  0.1708],\n",
      "        [-0.0785,  0.1000,  0.2419, -0.2128, -0.2332, -0.2254, -0.0963, -0.0551,\n",
      "         -0.0070, -0.2281,  0.0711,  0.0239, -0.1324,  0.0352, -0.0064,  0.0645],\n",
      "        [ 0.0276,  0.1491,  0.1075,  0.0228,  0.0873,  0.0702, -0.0642, -0.2191,\n",
      "          0.0692, -0.0507, -0.1266, -0.1735,  0.1510, -0.1308, -0.0139, -0.0655],\n",
      "        [ 0.1867, -0.0950, -0.1485, -0.0655,  0.0707,  0.1729, -0.1753,  0.0866,\n",
      "          0.1088, -0.0510, -0.1891, -0.1408,  0.0438,  0.0952, -0.0446,  0.2253],\n",
      "        [ 0.0927,  0.0995, -0.0276,  0.0339,  0.1311, -0.2389,  0.0105,  0.0322,\n",
      "         -0.2485,  0.0754, -0.2481, -0.0451, -0.1972, -0.1487,  0.1460,  0.1433],\n",
      "        [ 0.1856,  0.1911,  0.0054,  0.0164,  0.0172,  0.2405,  0.1723,  0.1866,\n",
      "          0.1486, -0.1719, -0.2315, -0.1772, -0.0152,  0.2416,  0.0309,  0.0266],\n",
      "        [-0.1380,  0.0338,  0.1180,  0.1224,  0.2405, -0.2324,  0.0546,  0.0993,\n",
      "          0.2371,  0.1373, -0.1225, -0.0945,  0.2061,  0.1911,  0.2333,  0.2028],\n",
      "        [-0.0934,  0.2418,  0.1492, -0.0178,  0.0698, -0.0188, -0.1928,  0.2452,\n",
      "         -0.0698,  0.0087, -0.2131,  0.0292, -0.2016, -0.1707,  0.0656, -0.0907],\n",
      "        [-0.0937, -0.1529, -0.0338, -0.1464,  0.2267, -0.2448,  0.0448,  0.1152,\n",
      "         -0.0816, -0.2340,  0.0883, -0.1587, -0.0777,  0.1203,  0.0479, -0.1152],\n",
      "        [-0.2458,  0.0391,  0.0940,  0.2444,  0.2214, -0.1337,  0.0281, -0.2396,\n",
      "          0.1357, -0.1741, -0.1331,  0.0832,  0.2472, -0.0976, -0.0185, -0.0401],\n",
      "        [-0.1588,  0.1706, -0.0440,  0.1292, -0.0700,  0.1519, -0.0793,  0.2439,\n",
      "         -0.1247, -0.0204, -0.0297, -0.2364,  0.1683, -0.1319,  0.0029,  0.0695]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([16, 16]), (16, 1)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0061,  0.0514,  0.1105, -0.0665, -0.0956,  0.1483, -0.0336, -0.0375,\n",
      "        -0.1791, -0.2396, -0.2230, -0.1749, -0.1973, -0.1317,  0.0768, -0.1832],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([16]), (1,)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([[ 0.2003,  0.1329,  0.1355,  0.1913, -0.1645, -0.1208, -0.1890,  0.2349,\n",
      "         -0.1113, -0.0761,  0.1963, -0.1658,  0.0978,  0.0240,  0.0969,  0.2111],\n",
      "        [ 0.1419,  0.1681,  0.1175,  0.0050, -0.0986,  0.1291, -0.0985, -0.1188,\n",
      "         -0.0160,  0.2184,  0.0320,  0.1385,  0.1780,  0.2364,  0.0243,  0.0391],\n",
      "        [-0.2263,  0.1571,  0.0075,  0.1576,  0.1956, -0.1991, -0.2318, -0.1772,\n",
      "          0.1090,  0.1253, -0.0813,  0.2044, -0.2205, -0.2040,  0.1597, -0.0343],\n",
      "        [-0.2461,  0.1669,  0.1610, -0.0815,  0.2052, -0.1980, -0.0548, -0.0187,\n",
      "         -0.2121,  0.2214,  0.1406, -0.0941,  0.1658,  0.1456,  0.0016, -0.0106],\n",
      "        [-0.1468, -0.0524,  0.0542, -0.2043, -0.2008, -0.1289,  0.0081, -0.1973,\n",
      "          0.2261, -0.1716,  0.1800, -0.1854, -0.1613, -0.1894, -0.0767, -0.0913],\n",
      "        [ 0.0880,  0.1862, -0.2401,  0.2108,  0.1449,  0.1142,  0.2221, -0.1598,\n",
      "         -0.1579,  0.1926, -0.2307,  0.0176,  0.0344,  0.1621, -0.0740, -0.1747],\n",
      "        [-0.2159, -0.0936, -0.1311,  0.2306, -0.0885, -0.2416, -0.1538, -0.0772,\n",
      "          0.0862,  0.0353,  0.0806, -0.1854, -0.0123,  0.1477,  0.0575,  0.1651],\n",
      "        [ 0.0076, -0.2236,  0.0655, -0.1435, -0.0528, -0.0760,  0.0574,  0.0700,\n",
      "         -0.2125, -0.0763,  0.0983,  0.0160, -0.0246, -0.1348, -0.1248, -0.1753]],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([8, 16]), (16, 1)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29500>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'dim' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch.nn.parameter.Parameter'>,), (Parameter containing:\n",
      "tensor([ 0.0075,  0.0851, -0.1069, -0.2367,  0.1441,  0.1257, -0.1292, -0.1924],\n",
      "       requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method empty_strided of type object at 0x10f32c008>, (), (torch.Size([8]), (1,)), {'dtype': torch.float32, 'device': 'meta'}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d297c0>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29440>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_inference' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28e40>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method '_is_view' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True), FakeTensor(..., size=())), {}\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FakeTensor(..., size=(10, 8), requires_grad=True), Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)), Parameter(FakeTensor(..., size=(16,), requires_grad=True))), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>), FakeTensor(..., size=())), {}\n",
      "ExportFakeFunctionMode dispatching <function relu at 0x11c0df600>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'inplace': False}\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>), Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)), Parameter(FakeTensor(..., size=(16,), requires_grad=True))), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>), FakeTensor(..., size=())), {}\n",
      "ExportFakeFunctionMode dispatching <function relu at 0x11c0df600>, (), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), {'inplace': False}\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>), Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)), Parameter(FakeTensor(..., size=(8,), requires_grad=True))), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>), FakeTensor(..., size=())), {}\n",
      "ExportFakeFunctionMode dispatching <method 'add' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>), FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>)), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), grad_fn=<AddBackward0>),), None\n",
      "ExportFakeFunctionMode dispatching profiler._record_function_enter_new, (), ('create_aot_dispatcher_function (dynamo_timed)', None), {}\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_multithreading_enabled>, (), (False,), None\n",
      "ExportFakeFunctionMode dispatching <built-in method clone of type object at 0x10f32c008>, (), (tensor([250,   3, 204,  ...,   0,   0,   0], dtype=torch.uint8),), None\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([250,   3, 204,  ...,   0,   0,   0], dtype=torch.uint8),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>))), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching <function relu at 0x11c0df600>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))),), {'inplace': False}\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>))), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching <function relu at 0x11c0df600>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))),), {'inplace': False}\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>))), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching <method 'add' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8))))), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28ec0>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'view' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8)), torch.Size([10, 8])), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ([],), None\n",
      "ExportFakeFunctionMode dispatching <function Tensor.__repr__ at 0x119881a80>, (), (FakeTensor(..., size=(10, 8)),), {'tensor_contents': None}\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (Parameter(FakeTensor(..., device='meta', size=(16, 8), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (Parameter(FakeTensor(..., device='meta', size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (Parameter(FakeTensor(..., device='meta', size=(16, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (Parameter(FakeTensor(..., device='meta', size=(16,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (Parameter(FakeTensor(..., device='meta', size=(8, 16), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (Parameter(FakeTensor(..., device='meta', size=(8,), requires_grad=True)),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching <function relu at 0x11c0df600>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>))),), {'inplace': False}\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>))), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(16,), requires_grad=True)),\n",
      "       grad_fn=<Error>))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching <function relu at 0x11c0df600>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>))),), {'inplace': False}\n",
      "ExportFakeFunctionMode dispatching <built-in function linear>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16), grad_fn=<ReluBackward0>))), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(Parameter(FakeTensor(..., size=(8,), requires_grad=True)),\n",
      "       grad_fn=<Error>))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__wrapper__torch__C__nn_linear__4713105744_defaultBackward>))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching <method 'add' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8),\n",
      "           grad_fn=<GeneratedBackwardFor_auto_norm_op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152_defaultBackward>)))), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_multithreading_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching profiler._record_function_exit._RecordFunction, (), (<torch.ScriptObject object at 0x16e1a8260>,), {}\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 8), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(16,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8, 16), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (Parameter(FakeTensor(..., size=(8,), requires_grad=True)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)), True), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()), False), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()), False), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()), False), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()), False), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__set__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)), True), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (False,), None\n",
      "ExportFakeFunctionMode dispatching profiler._record_function_enter_new, (), ('create_aot_dispatcher_function (dynamo_timed)', None), {}\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_multithreading_enabled>, (), (False,), None\n",
      "ExportFakeFunctionMode dispatching <built-in method clone of type object at 0x10f32c008>, (), (tensor([250,   3, 204,  ...,   0,   0,   0], dtype=torch.uint8),), None\n",
      "ExportFakeFunctionMode dispatching <method 'data_ptr' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (tensor([250,   3, 204,  ...,   0,   0,   0], dtype=torch.uint8),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__wrapper__torch__C__nn_linear__4713105744.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching aten.relu.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))),), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__wrapper__torch__C__nn_linear__4713105744.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching aten.relu.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))),), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__wrapper__torch__C__nn_linear__4713105744.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching aten.add.Tensor, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8))))), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28c80>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=()))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'untyped_storage' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_conj' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_neg' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28b80>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d28ec0>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ([],), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'detach' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=(16, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=(16, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,), requires_grad=True),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=(8, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=(8,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,), requires_grad=True),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,), requires_grad=True),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,), requires_grad=True),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'numel' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching aten.detach.default, (), (FakeTensor(..., device='meta', size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (tensor(..., device='meta', size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.channels_last_3d}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.channels_last}\n",
      "ExportFakeFunctionMode dispatching <method 'is_contiguous' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {'memory_format': torch.contiguous_format}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29700>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8), requires_grad=True),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(16,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8, 16), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(8,), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=()),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=())),), None\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching prim.device.default, (), (FakeTensor(..., size=(10, 8), requires_grad=True),), {}\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29100>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29840>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d298c0>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29000>, (<class 'torch.Tensor'>,), (_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>),), None\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__wrapper__torch__C__nn_linear__4713105744.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16, 8), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching aten.relu.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))),), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__wrapper__torch__C__nn_linear__4713105744.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16, 16), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(16,), requires_grad=True),\n",
      "       grad_fn=<Error>))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching aten.relu.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))),), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__wrapper__torch__C__nn_linear__4713105744.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 16)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(8, 16), requires_grad=True),\n",
      "       grad_fn=<Error>)), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(8,), requires_grad=True),\n",
      "       grad_fn=<Error>))), {}\n",
      "ExportFakeFunctionMode dispatching auto_norm.op__constant_scaler_mul__auto_norm_reg_fake_norm_ops_constant_scaler_ConstantScaler__mul_with_scaler__13174249152.default, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=())))), {}\n",
      "ExportFakeFunctionMode dispatching aten.add.Tensor, (), (FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8)))), FunctionalTensor(_to_functional_tensor(FakeTensor(..., size=(10, 8))))), {}\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in method tensor of type object at 0x10f32c008>, (), ((),), None\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_multithreading_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching profiler._record_function_exit._RecordFunction, (), (<torch.ScriptObject object at 0x16e4b4150>,), {}\n",
      "ExportFakeFunctionMode dispatching <built-in function _set_grad_enabled>, (), (True,), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(16,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8, 16)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(8,)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=()),), None\n",
      "ExportFakeFunctionMode dispatching <method 'size' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method-wrapper '__get__' of getset_descriptor object at 0x106d29880>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'stride' of 'torch._C.TensorBase' objects>, (), (FakeTensor(..., size=(10, 8)),), None\n",
      "ExportFakeFunctionMode dispatching <method 'storage_offset' of 'torch._C.TensorBase' objects>, (<class 'torch._subclasses.fake_tensor.FakeTensor'>,), (FakeTensor(..., size=(10, 8)),), None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyResBlockWithScaling(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (1): ConstantScaler()\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (4): ConstantScaler()\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (7): ConstantScaler()\n",
       "  )\n",
       "  (idt_scaler): ConstantScaler()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyResBlockWithScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            auto_norm.ConstantScaler(),  # insert scales at places we want to tune. by default, it is noop\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            auto_norm.ConstantScaler(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            auto_norm.ConstantScaler(),\n",
    "        )\n",
    "        self.idt_scaler = auto_norm.ConstantScaler()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.idt_scaler(x) + self.net(x)\n",
    "\n",
    "\n",
    "scaled_net = MyResBlockWithScaling()\n",
    "norm_map_for_scaled_net = auto_norm.build_norm_map(scaled_net, example_input)\n",
    "scaled_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the state dict contains these new scale factor. We can send any scale factors to a `norm_map` via the normed state dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_normed_state_dict_for_scaled_net(post_linear_scale, idt_scale):\n",
    "    normed_state_dict = {}\n",
    "    for name in scaled_net.state_dict():\n",
    "        if name.endswith('weight'):\n",
    "            normed_state_dict[name] = auto_norm.RMS_RMS_NormTensor(1, elem_dims=(-1, -2))\n",
    "        elif name.endswith('bias'):\n",
    "            normed_state_dict[name] = auto_norm.RMS_NormTensor(0, elem_dims=(-1,))\n",
    "        elif name == 'idt_scaler.scale':\n",
    "            normed_state_dict[name] = idt_scale\n",
    "        elif name.endswith('scale'):\n",
    "            normed_state_dict[name] = post_linear_scale\n",
    "    return normed_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the current output norm is the same as without the scaler (since they default to scale=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "output_norm: \n",
      " RMS_NormTensor(\n",
      "    norm_size=tensor(1.5000),\n",
      "    elem_dims=(1,),\n",
      "    unwrapped=FakeTensor(..., size=(10, 8)),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "normed_state_dict = build_normed_state_dict_for_scaled_net(post_linear_scale=torch.tensor(1.), idt_scale=torch.tensor(1.))\n",
    "\n",
    "\n",
    "output_norm = norm_map_for_scaled_net(normed_input, normed_state_dict=normed_state_dict)\n",
    "print('output_norm: \\n', output_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tune the scaling factors so that the output norm becomes 1!\n",
    "\n",
    "First, let's prepare the normed state dict with scale factors that require grad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normed_state_dict:\n",
      "{'idt_scaler.scale': tensor(1., requires_grad=True),\n",
      " 'net.0.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.0.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.1.scale': tensor(1., requires_grad=True),\n",
      " 'net.3.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.3.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.4.scale': tensor(1., requires_grad=True),\n",
      " 'net.6.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.6.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.7.scale': tensor(1., requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "post_linear_scale = torch.tensor(1., requires_grad=True)  # requres grad!\n",
    "idt_scale = torch.tensor(1., requires_grad=True)\n",
    "normed_state_dict = build_normed_state_dict_for_scaled_net(post_linear_scale, idt_scale)\n",
    "print('normed_state_dict:')\n",
    "pprint(normed_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, simply optimize with autograd..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "iter 050: loss=0.0000 output_norm=1.0013\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "iter 100: loss=0.0000 output_norm=1.0000\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "iter 150: loss=0.0000 output_norm=1.0000\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.div.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add_.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, scale: torch.Tensor) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "TensorSubclassDispatcher dispatching (input: torch.Tensor, other: torch.Tensor, *, alpha: numbers.Number = 1) -> torch.Tensor\n",
      "NormPropagateDispatchMode: aten.mul.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.add.Tensor, ()\n",
      "NormPropagateDispatchMode: aten.empty.memory_format, ()\n",
      "iter 200: loss=0.0000 output_norm=1.0000\n",
      "post_linear_scale: \n",
      " tensor(0.7534, requires_grad=True)\n",
      "idt_scale: \n",
      " tensor(0.7862, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.SGD([post_linear_scale, idt_scale], lr=0.03)\n",
    "for ii in range(1, 201):\n",
    "    optim.zero_grad()\n",
    "    output_norm = norm_map_for_scaled_net(normed_input, normed_state_dict=normed_state_dict)\n",
    "    loss = F.mse_loss(output_norm.norm_size, torch.tensor(1.))\n",
    "    if ii % 50 == 0:\n",
    "        print(f'iter {ii:03d}: loss={loss:.4f} output_norm={output_norm.norm_size:.4f}')\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "print('post_linear_scale: \\n', post_linear_scale)\n",
    "print('idt_scale: \\n', idt_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that they works manually too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_output_norm: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "manual_output_norm = (\n",
    "    (scaler_contribution := post_linear_scale ** 3) *\n",
    "    (relu_contribution := (1 / math.sqrt(2)) ** 2) +\n",
    "    (idt_contribution := idt_scale)\n",
    ")\n",
    "assert torch.allclose(manual_output_norm, torch.tensor(1.))\n",
    "print(f'manual_output_norm: {manual_output_norm:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
